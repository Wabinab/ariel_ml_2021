{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GCLOUD_PROJECT=sunlit-analyst-309609\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"sunlit-analyst-309609\"\n",
    "%env GCLOUD_PROJECT=$PROJECT_ID\n",
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from google.cloud import bigquery\n",
    "LOCATION = \"us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "\n",
    "bqclient = bigquery.Client()\n",
    "bqstorageclient = bigquery_storage.BigQueryReadClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing \n",
    "\n",
    "This is a testing to see whether we can directly choose columns in pandas correctly so we don't have to call from biquery for each and every record, which is much more expensive in terms of time and cost than fetching all into pandas before doing manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.02s: 100%|██████████| 1/1 [00:00<00:00, 289.40query/s]\n",
      "Downloading: 100%|██████████| 125600/125600 [00:10<00:00, 11711.64rows/s]\n"
     ]
    }
   ],
   "source": [
    "# %%bigquery df --use_bqstorage_api\n",
    "# SELECT * EXCEPT (BB, CC, label),\n",
    "# FROM `sunlit-analyst-309609.training_set.train_table_0` a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5008592 , 0.7240773 , 0.80981546, ..., 1.00277082, 0.99809756,\n",
       "       0.99494013])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array(df.loc[df[\"AAAA\"] == 2])[:, 1:].flatten()\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAA</th>\n",
       "      <th>_0</th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_4</th>\n",
       "      <th>_5</th>\n",
       "      <th>_6</th>\n",
       "      <th>_7</th>\n",
       "      <th>_8</th>\n",
       "      <th>...</th>\n",
       "      <th>_290</th>\n",
       "      <th>_291</th>\n",
       "      <th>_292</th>\n",
       "      <th>_293</th>\n",
       "      <th>_294</th>\n",
       "      <th>_295</th>\n",
       "      <th>_296</th>\n",
       "      <th>_297</th>\n",
       "      <th>_298</th>\n",
       "      <th>_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84900</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504461</td>\n",
       "      <td>0.724235</td>\n",
       "      <td>0.812151</td>\n",
       "      <td>0.874932</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>0.941855</td>\n",
       "      <td>0.958407</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.982835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000463</td>\n",
       "      <td>1.001674</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.998099</td>\n",
       "      <td>0.998742</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.996169</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>1.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84901</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504430</td>\n",
       "      <td>0.721806</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.916751</td>\n",
       "      <td>0.939872</td>\n",
       "      <td>0.962460</td>\n",
       "      <td>0.971361</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.998557</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>1.000704</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.001793</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>1.001757</td>\n",
       "      <td>0.999277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84902</th>\n",
       "      <td>1</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>0.723826</td>\n",
       "      <td>0.814340</td>\n",
       "      <td>0.877008</td>\n",
       "      <td>0.915292</td>\n",
       "      <td>0.942762</td>\n",
       "      <td>0.961914</td>\n",
       "      <td>0.976532</td>\n",
       "      <td>0.980890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000808</td>\n",
       "      <td>1.000796</td>\n",
       "      <td>1.000034</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>1.003238</td>\n",
       "      <td>1.000333</td>\n",
       "      <td>0.996227</td>\n",
       "      <td>1.000776</td>\n",
       "      <td>1.000648</td>\n",
       "      <td>0.997978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84903</th>\n",
       "      <td>1</td>\n",
       "      <td>0.503904</td>\n",
       "      <td>0.724010</td>\n",
       "      <td>0.818815</td>\n",
       "      <td>0.875103</td>\n",
       "      <td>0.916524</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>0.961877</td>\n",
       "      <td>0.979034</td>\n",
       "      <td>0.983156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000276</td>\n",
       "      <td>1.000465</td>\n",
       "      <td>1.003728</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>1.001472</td>\n",
       "      <td>1.001827</td>\n",
       "      <td>1.000461</td>\n",
       "      <td>0.998925</td>\n",
       "      <td>1.004878</td>\n",
       "      <td>1.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84904</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504843</td>\n",
       "      <td>0.722748</td>\n",
       "      <td>0.815991</td>\n",
       "      <td>0.874753</td>\n",
       "      <td>0.916074</td>\n",
       "      <td>0.941788</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.974698</td>\n",
       "      <td>0.980729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.997249</td>\n",
       "      <td>1.001838</td>\n",
       "      <td>1.000093</td>\n",
       "      <td>1.000956</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>1.002111</td>\n",
       "      <td>1.002540</td>\n",
       "      <td>0.999237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504291</td>\n",
       "      <td>0.719412</td>\n",
       "      <td>0.814134</td>\n",
       "      <td>0.875120</td>\n",
       "      <td>0.915518</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>0.964959</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>0.985015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002032</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>1.004072</td>\n",
       "      <td>1.000762</td>\n",
       "      <td>0.998163</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>1.001428</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>1.000547</td>\n",
       "      <td>1.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504484</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.813124</td>\n",
       "      <td>0.876769</td>\n",
       "      <td>0.914985</td>\n",
       "      <td>0.943828</td>\n",
       "      <td>0.962988</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.984346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>1.002097</td>\n",
       "      <td>1.005057</td>\n",
       "      <td>1.003266</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.998699</td>\n",
       "      <td>1.001919</td>\n",
       "      <td>1.001269</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>1.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84997</th>\n",
       "      <td>1</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.719754</td>\n",
       "      <td>0.814797</td>\n",
       "      <td>0.877259</td>\n",
       "      <td>0.918352</td>\n",
       "      <td>0.944720</td>\n",
       "      <td>0.960349</td>\n",
       "      <td>0.975839</td>\n",
       "      <td>0.985077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995653</td>\n",
       "      <td>0.997679</td>\n",
       "      <td>1.001844</td>\n",
       "      <td>1.000364</td>\n",
       "      <td>0.997459</td>\n",
       "      <td>0.998965</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>1.000025</td>\n",
       "      <td>1.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.505423</td>\n",
       "      <td>0.719267</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.872393</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>0.941603</td>\n",
       "      <td>0.958838</td>\n",
       "      <td>0.974763</td>\n",
       "      <td>0.982734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000370</td>\n",
       "      <td>1.000844</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>1.001354</td>\n",
       "      <td>1.001642</td>\n",
       "      <td>1.001803</td>\n",
       "      <td>1.000853</td>\n",
       "      <td>1.001467</td>\n",
       "      <td>1.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.503186</td>\n",
       "      <td>0.721306</td>\n",
       "      <td>0.813928</td>\n",
       "      <td>0.872228</td>\n",
       "      <td>0.915925</td>\n",
       "      <td>0.944308</td>\n",
       "      <td>0.957616</td>\n",
       "      <td>0.976927</td>\n",
       "      <td>0.979183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>0.998315</td>\n",
       "      <td>1.004306</td>\n",
       "      <td>1.001132</td>\n",
       "      <td>1.003096</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>0.998250</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>1.001132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAA        _0        _1        _2        _3        _4        _5  \\\n",
       "84900     1  0.504461  0.724235  0.812151  0.874932  0.911667  0.941855   \n",
       "84901     1  0.504430  0.721806  0.812968  0.873251  0.916751  0.939872   \n",
       "84902     1  0.501610  0.723826  0.814340  0.877008  0.915292  0.942762   \n",
       "84903     1  0.503904  0.724010  0.818815  0.875103  0.916524  0.941748   \n",
       "84904     1  0.504843  0.722748  0.815991  0.874753  0.916074  0.941788   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "84995     1  0.504291  0.719412  0.814134  0.875120  0.915518  0.943900   \n",
       "84996     1  0.504484  0.721519  0.813124  0.876769  0.914985  0.943828   \n",
       "84997     1  0.502171  0.719754  0.814797  0.877259  0.918352  0.944720   \n",
       "84998     1  0.505423  0.719267  0.811880  0.872393  0.914324  0.941603   \n",
       "84999     1  0.503186  0.721306  0.813928  0.872228  0.915925  0.944308   \n",
       "\n",
       "             _6        _7        _8  ...      _290      _291      _292  \\\n",
       "84900  0.958407  0.970852  0.982835  ...  1.000463  1.001674  0.998899   \n",
       "84901  0.962460  0.971361  0.982808  ...  0.998978  0.998557  0.999303   \n",
       "84902  0.961914  0.976532  0.980890  ...  1.000808  1.000796  1.000034   \n",
       "84903  0.961877  0.979034  0.983156  ...  1.000276  1.000465  1.003728   \n",
       "84904  0.960547  0.974698  0.980729  ...  0.999965  0.996774  0.997249   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "84995  0.964959  0.976067  0.985015  ...  1.002032  0.997889  1.004072   \n",
       "84996  0.962988  0.976755  0.984346  ...  0.998478  1.002097  1.005057   \n",
       "84997  0.960349  0.975839  0.985077  ...  0.995653  0.997679  1.001844   \n",
       "84998  0.958838  0.974763  0.982734  ...  1.000370  1.000844  0.998721   \n",
       "84999  0.957616  0.976927  0.979183  ...  0.999691  1.000241  0.998315   \n",
       "\n",
       "           _293      _294      _295      _296      _297      _298      _299  \n",
       "84900  0.999176  0.998099  0.998742  0.999880  0.996169  0.998923  1.000007  \n",
       "84901  1.000704  0.999658  1.001793  0.998248  0.999198  1.001757  0.999277  \n",
       "84902  0.998788  1.003238  1.000333  0.996227  1.000776  1.000648  0.997978  \n",
       "84903  0.999946  1.001472  1.001827  1.000461  0.998925  1.004878  1.001769  \n",
       "84904  1.001838  1.000093  1.000956  0.999395  1.002111  1.002540  0.999237  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "84995  1.000762  0.998163  0.999086  1.001428  0.999111  1.000547  1.000504  \n",
       "84996  1.003266  0.998325  0.998699  1.001919  1.001269  0.999770  1.001834  \n",
       "84997  1.000364  0.997459  0.998965  0.996914  0.999438  1.000025  1.000820  \n",
       "84998  0.997314  1.001354  1.001642  1.001803  1.000853  1.001467  1.000607  \n",
       "84999  1.004306  1.001132  1.003096  1.001341  0.998250  0.998743  1.001132  \n",
       "\n",
       "[100 rows x 301 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df[\"AAAA\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 1314.21query/s]\n",
      "Downloading: 100%|██████████| 1256/1256 [00:01<00:00, 1135.60rows/s]\n"
     ]
    }
   ],
   "source": [
    "# %%bigquery label --use_bqstorage_api\n",
    "# SELECT DISTINCT AAAA, label\n",
    "# FROM `sunlit-analyst-309609.training_set.train_table_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.05427012)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b = np.array(label.loc[label[\"AAAA\"] == 1])[:, 1:].squeeze()\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30001)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.append(a, b).reshape((1, -1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmation success\n",
    "Corfirmation is now success. Next is to create the csv file from which we could load from this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./csv_files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, select all distinct AAAA that we would like to use as iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 1/1 [00:00<00:00, 675.19query/s] \n",
      "Downloading: 100%|██████████| 1256/1256 [00:01<00:00, 994.40rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery AAAAs --use_bqstorage_api\n",
    "SELECT DISTINCT AAAA\n",
    "FROM`sunlit-analyst-309609.training_set.train_table_0`\n",
    "ORDER BY AAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# for i in AAAAs.values.flatten():\n",
    "#     print(i)\n",
    "\n",
    "#     if i > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1256/1256 [02:37<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 3.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_csv(f) :\n",
    "    for table_name in f:\n",
    "        query_string = f\"\"\"\n",
    "        SELECT * EXCEPT (BB, CC, label),\n",
    "        FROM `sunlit-analyst-309609.training_set.train_table_{table_name}`\n",
    "        \"\"\"\n",
    "\n",
    "        df = (\n",
    "            bqclient.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(bqstorage_client=bqstorageclient)\n",
    "        )\n",
    "\n",
    "        query_string = f\"\"\"\n",
    "        SELECT DISTINCT AAAA, label\n",
    "        FROM `sunlit-analyst-309609.training_set.train_table_{table_name}`\n",
    "        \"\"\"\n",
    "\n",
    "        target = (\n",
    "            bqclient.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(bqstorage_client=bqstorageclient)\n",
    "        )\n",
    "\n",
    "        for AAAA in tqdm(AAAAs.values.flatten()):\n",
    "            main_array = np.array(df.loc[df[\"AAAA\"] == AAAA])[:, 1:].flatten()\n",
    "\n",
    "            side_array = np.array(target.loc[target[\"AAAA\"] == AAAA])[:, 1:].squeeze()\n",
    "\n",
    "            total_array = np.append(main_array, side_array).reshape((1, -1))\n",
    "\n",
    "            assert total_array.shape == (1, 30001)\n",
    "\n",
    "            # Convert to pandas DataFrame\n",
    "            total_array = pd.DataFrame(total_array, dtype=\"float\")\n",
    "\n",
    "            total_array.to_csv(folder + f\"flatten_train_{table_name}.csv\", header=False, index=False, mode=\"a\", sep=\",\")\n",
    "\n",
    "        print(f\"\\nDone with table {table_name}.\\n\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# def call_multiprocessing(processes):\n",
    "#     params = np.array_split(np.arange(55), processes)\n",
    "\n",
    "#     with Pool(processes) as pool:\n",
    "#         results = pool.map(flatten_to_csv, params)\n",
    "\n",
    "\n",
    "# call_multiprocessing(2)\n",
    "flatten_to_csv([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assert the files and see that the shape is as we expected. Be aware that this is not an efficient test as you consider how much GB of data we are reading just to make the assertions. But since we are only running it for one time and never again we don't care that much, time is sufficient to spare (ahem, waste). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 30001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pd.read_csv(f\"./csv_files/flatten_train_3.csv\", header=None)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [13:14<00:00, 29.43s/it]\n",
      "100%|██████████| 28/28 [13:41<00:00, 29.33s/it]\n"
     ]
    }
   ],
   "source": [
    "def test_ours(a):\n",
    "    for table_name in tqdm(a):\n",
    "        assert np.array(pd.read_csv(f\"./csv_files/flatten_train_{table_name}.csv\", header=None)).shape == (1256, 30001)\n",
    "\n",
    "    return None\n",
    "\n",
    "def driver_func():\n",
    "    # processes = os.cpu_count()\n",
    "    processes = 2\n",
    "    params = np.array_split(np.arange(55), processes)\n",
    "\n",
    "    with Pool(processes) as pool:\n",
    "        results = pool.map(test_ours, params)\n",
    "\n",
    "\n",
    "driver_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to upload them to bigquery dataset. Refer to https://www.kaggle.com/rtatman/uploading-csv-to-bigquery for the original code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_id = \"flatten_train\"\n",
    "# bqclient.create_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = bqclient  # due to copying, uneven in naming. (inconsistency)\n",
    "\n",
    "# def upload_to_bigquery(f):\n",
    "#     for table_name in f:\n",
    "\n",
    "#         table_id = f\"flatten_train_{table_name}\"\n",
    "#         filename = f\"./csv_files/flatten_train_{table_name}.csv\"\n",
    "\n",
    "#         # Create new table in that dataset\n",
    "#         client.create_table(f\"{PROJECT_ID}.{dataset_id}.{table_id}\")\n",
    "        \n",
    "#         # Tell the client everything it needs to know to upload our csv. \n",
    "#         dataset_ref = client.dataset(dataset_id)\n",
    "#         table_ref = dataset_ref.table(table_id)\n",
    "#         job_config = bigquery.LoadJobConfig()\n",
    "#         job_config.source_format = bigquery.SourceFormat.CSV\n",
    "#         job_config.autodetect = True  # Actually no use since we are not saving a header. \n",
    "\n",
    "#         # Load csv into bigquery. \n",
    "#         with open(filename, \"rb\") as source_file:\n",
    "#             job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "#         job.result()  # Waits for table load to complete. \n",
    "\n",
    "#         # Check everything works. \n",
    "#         print(f\"Loaded {job.output_rows} rows into {dataset_id}:{table_id}.\")\n",
    "#         print(f\"Finish loading table {table_name}.\\n\")\n",
    "\n",
    "\n",
    "# def multiprocess_call(processes):\n",
    "#     # processes = 2\n",
    "#     params = np.array_split(np.arange(55), processes)\n",
    "\n",
    "#     with Pool(processes) as pool:\n",
    "#         pool.map(upload_to_bigquery, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Number of columns 30001 is too many for table 'flatten_train_19_6cf8f528_a70c_4a62_bb6c_c787b543d081_source'. A table must have no more than 10000 columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-102-466e4d683db4>\", line 23, in upload_to_bigquery\n    job.result()  # Waits for table load to complete.\n  File \"/home/chowjunwei37/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py\", line 679, in result\n    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)\n  File \"/home/chowjunwei37/.local/lib/python3.7/site-packages/google/api_core/future/polling.py\", line 134, in result\n    raise self._exception\ngoogle.api_core.exceptions.BadRequest: 400 Number of columns 30001 is too many for table 'flatten_train_19_6cf8f528_a70c_4a62_bb6c_c787b543d081_source'. A table must have no more than 10000 columns.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-3ee02b456386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-466e4d683db4>\u001b[0m in \u001b[0;36mmultiprocess_call\u001b[0;34m(processes)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_to_bigquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Number of columns 30001 is too many for table 'flatten_train_19_6cf8f528_a70c_4a62_bb6c_c787b543d081_source'. A table must have no more than 10000 columns."
     ]
    }
   ],
   "source": [
    "# multiprocess_call(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can go to bigquery and check that everything is there. Violà! \n",
    "\n",
    "Note that however the above process is not fail-safe. There had been ignored try-except blocks that can make it fail-safe but not in place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "Well, it seems like it failed to load to BigQuery, so we have to load from csv instead. \n",
    "\n",
    "# Do the same for test files\n",
    "Remember we have a different AAAAs for this so we need to load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 947.65query/s] \n",
      "Downloading: 100%|██████████| 539/539 [00:01<00:00, 353.61rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery AAAAs --use_bqstorage_api\n",
    "SELECT DISTINCT AAAA\n",
    "FROM`sunlit-analyst-309609.test_set.test_table_0`\n",
    "ORDER BY AAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 5.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 6.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 7.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 8.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 9.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:07<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 10.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 11.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 12.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 13.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 14.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 15.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 16.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 17.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 18.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 19.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 20.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 21.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 22.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 23.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:58<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 24.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 25.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 26.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:00<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 27.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:07<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 28.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 29.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 30.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 31.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 32.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 33.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 34.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 35.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 36.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:08<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 37.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 38.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:56<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 39.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:56<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 40.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:56<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 41.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:04<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 42.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 43.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 44.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 45.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 46.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 47.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 48.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 49.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 50.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [01:05<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 51.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:57<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 52.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:56<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 53.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:56<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with table 54.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"./csv_files_test/\"\n",
    "\n",
    "\n",
    "def flatten_to_csv(f) :\n",
    "    for table_name in f:\n",
    "        query_string = f\"\"\"\n",
    "        SELECT * EXCEPT (BB, CC),\n",
    "        FROM `sunlit-analyst-309609.test_set.test_table_{table_name}`\n",
    "        \"\"\"\n",
    "\n",
    "        df = (\n",
    "            bqclient.query(query_string)\n",
    "            .result()\n",
    "            .to_dataframe(bqstorage_client=bqstorageclient)\n",
    "        )\n",
    "\n",
    "        for AAAA in tqdm(AAAAs.values.flatten()):\n",
    "            total_array = np.array(df.loc[df[\"AAAA\"] == AAAA])[:, 1:].flatten().reshape((1, -1))\n",
    "\n",
    "            assert total_array.shape == (1, 30000)\n",
    "\n",
    "            # Convert to pandas DataFrame\n",
    "            total_array = pd.DataFrame(total_array, dtype=\"float\")\n",
    "\n",
    "            total_array.to_csv(test_folder + f\"flatten_test_{table_name}.csv\", header=False, index=False, mode=\"a\", sep=\",\")\n",
    "\n",
    "        print(f\"\\nDone with table {table_name}.\\n\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# def call_multiprocessing(processes):\n",
    "#     params = np.array_split(np.arange(55), processes)\n",
    "\n",
    "#     with Pool(processes) as pool:\n",
    "#         results = pool.map(flatten_to_csv, params)\n",
    "\n",
    "\n",
    "# call_multiprocessing(2)\n",
    "flatten_to_csv(range(5, 55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ours(a):\n",
    "    for table_name in tqdm(a):\n",
    "        assert np.array(pd.read_csv(f\"./csv_files_test/flatten_test_{table_name}.csv\", header=None)).shape == (539, 30000)\n",
    "\n",
    "    return None\n",
    "\n",
    "def driver_func():\n",
    "    # processes = os.cpu_count()\n",
    "    processes = 2\n",
    "    params = np.array_split(np.arange(55), processes)\n",
    "\n",
    "    with Pool(processes) as pool:\n",
    "        results = pool.map(test_ours, params)\n",
    "\n",
    "\n",
    "# driver_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
