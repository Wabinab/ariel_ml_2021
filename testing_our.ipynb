{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import itertools\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# project_dir = pathlib.Path(__file__).parent.absolute()\n",
    "\n",
    "# paths to data dirs\n",
    "# lc_train_path = \"/home/dsvm113/IdeaProjects/workspace/data_1/training_set/noisy_train/\"\n",
    "# params_train_path = \"/home/dsvm113/IdeaProjects/workspace/data_1/training_set/params_train/\"\n",
    "lc_train_path = \"./data/noisy_train/\"\n",
    "params_train_path = \"./data/params_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "tfms = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "img = tfms(Image.open('data/0001_01.png')).unsqueeze(0)\n",
    "print(img.shape) # torch.Size([1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "torch.Size([1, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "\n",
    "features = model.extract_features(img)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lc_path = lc_train_path + \"0100_01_01.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt(item_lc_path)\n",
    "test = torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 300])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5048, 0.7209, 0.8134,  ..., 1.0003, 0.9997, 0.9991],\n",
       "         [0.5039, 0.7216, 0.8138,  ..., 0.9991, 1.0003, 1.0003],\n",
       "         [0.5042, 0.7222, 0.8142,  ..., 1.0002, 1.0004, 0.9994],\n",
       "         ...,\n",
       "         [0.5041, 0.7236, 0.8173,  ..., 0.9990, 0.9977, 0.9982],\n",
       "         [0.5043, 0.7202, 0.8123,  ..., 0.9975, 1.0022, 1.0007],\n",
       "         [0.5037, 0.7238, 0.8101,  ..., 1.0021, 1.0060, 1.0080]],\n",
       "        dtype=torch.float64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some = torch.split(test, 55)\n",
    "some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(item_lc_path, \"r\") as f:\n",
    "    temp_storage_str = list(itertools.islice(f, 6))\n",
    "\n",
    "temp_storage_float = []\n",
    "\n",
    "for string in temp_storage_str:\n",
    "    # Separate the digits and the non-digits.\n",
    "    new_str = [\"\".join(x) for _, x in itertools.groupby(string, key=str.isdigit)]\n",
    "\n",
    "    # Only new_str[0] is the one we want to omit.\n",
    "    # We want to join back into a single string because \".\" previously is classifed\n",
    "    # as non-digit. \n",
    "    new_str = \"\".join(new_str[1:])  \n",
    "\n",
    "    # Convert to float. \n",
    "    temp_storage_float.append(float(new_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4880.0, 4.5, 0.73, 0.77, 9.688, 6.67202]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_storage_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4880.0, 0.73, 0.77, 9.688, 6.67202]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_storage_float.pop(-5)\n",
    "temp_storage_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4880.0, 0, 0.77, 9.688, 6.67202]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if temp_storage_float[-4] > 0.5:\n",
    "    temp_storage_float[-4] = 0\n",
    "\n",
    "temp_storage_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.88000e+03, 0.00000e+00, 7.70000e-01, 9.68800e+00, 6.67202e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_numpy = np.array(temp_storage_float)\n",
    "temp_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.88000e+03, 0.00000e+00, 7.70000e-01, 9.68800e+00, 6.67202e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(temp_numpy[-2] > 10, 0, temp_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineConv(\n",
       "  (layer1): Conv1d(16505, 1024, kernel_size=(1,), stride=(2,))\n",
       "  (act1): ReLU()\n",
       "  (layer2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "  (act2): ReLU()\n",
       "  (layer3): Linear(in_features=256, out_features=55, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "    \n",
    "from pathlib import Path\n",
    "\n",
    "from utils import BaselineConv\n",
    "\n",
    "baseline = BaselineConv().double().to(\"cpu\")\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c28c176a6561e0f599baf12f61c08a38880cae9f7d0fc7d3751de036b3a31dd1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('py38_pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}